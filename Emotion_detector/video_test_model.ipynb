{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_test_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Sno9u2uKAp_mQ_qX490YGCOlfFrHUoBO",
      "authorship_tag": "ABX9TyPNA0CRiuXBEdvl/f4kQKa3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanJoaoPedro/Deep-Learning-Python/blob/master/Emotion_detector/video_test_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzKM7pgsc5cp",
        "colab_type": "text"
      },
      "source": [
        "# Importing libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqyc5tKZZB1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Keai38UNA6-j",
        "colab_type": "text"
      },
      "source": [
        "# Accessing the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f1sXX1Jdnll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3257b39-a96b-4662-b44b-61593d94ef83"
      },
      "source": [
        "path = '/content/drive/My Drive/teste_modelo.zip'\n",
        "zip_object = zipfile.ZipFile(file=path)\n",
        "zip_object.extractall('./')\n",
        "zip_object.close"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method ZipFile.close of <zipfile.ZipFile filename='/content/drive/My Drive/teste_modelo.zip' mode='r'>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbT0RmzFfBlh",
        "colab_type": "text"
      },
      "source": [
        "# Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJVzQyCzeyhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/modelo_04_expressoes.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGFeIHCsgP4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m0X5wPRh25f",
        "colab_type": "text"
      },
      "source": [
        "# Loading video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z85QblkNgUhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1deb95bc-005f-4ce1-f1ae-b734a83da9b8"
      },
      "source": [
        "file_video = '/content/video_teste05.mp4'\n",
        "capture = cv2.VideoCapture(file_video)\n",
        "\n",
        "connected, video = capture.read()\n",
        "print(connected, video.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True (480, 854, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCgysIvLit0m",
        "colab_type": "text"
      },
      "source": [
        "# Video resizing to decrease processing time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl4jQXGljarF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resizing = True\n",
        "maximum_width = 600\n",
        "\n",
        "if (resizing and video.shape[1] > maximum_width):\n",
        "    proportion = video.shape[1] / video.shape[0]\n",
        "    video_width = maximum_width\n",
        "    video_height = int(video_width / proportion)\n",
        "else:\n",
        "    video_width = video.shape[1]\n",
        "    video_height = video.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLTJnIcQmf3z",
        "colab_type": "text"
      },
      "source": [
        "# Defining the video settings\n",
        "\n",
        "**Codecs :**\n",
        "\n",
        "A FourCC is a four-byte string used to uniquely identify data formats\n",
        "\n",
        "Most used codecs: XVID, MP4V, MJPG, DIVX, X264 ...\n",
        "\n",
        "Example: To save in mp4 format, the MP4V codec is used (The file name also needs the .mp4 extension)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd0rW6NFmbLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = 'result_video_test.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "fps = 64\n",
        "output_video = cv2.VideoWriter(file_name, fourcc, fps, (video_width, video_height))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tls5YUNMq3ea",
        "colab_type": "text"
      },
      "source": [
        "# Video processing and recording of the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ivNWu5bquH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "haarcascade_faces = '/content/haarcascade_frontalface_default.xml'\n",
        "small_font, medium_font = 0.4, 0.7\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "expression = ['Raiva', 'Nojo', 'Medo', 'Feliz', 'Triste', 'Surpreso', 'Neutro']\n",
        "\n",
        "while (cv2.waitKey(1) <0 ):\n",
        "    connected, frame = capture.read()\n",
        "\n",
        "    if not connected:\n",
        "        break\n",
        "    \n",
        "    t = time.time()\n",
        "\n",
        "    if resizing:\n",
        "        frame = cv2.resize(frame, (video_width, video_height))\n",
        "\n",
        "    face_cascade = cv2.CascadeClassifier(haarcascade_faces)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(30,30))\n",
        "\n",
        "    if len(faces) > 0:\n",
        "        for (x, y, w, h) in faces:\n",
        "            frame = cv2.rectangle(frame, (x,y), (x + w, y + h + 10), (255, 50, 50), 2)\n",
        "            region_of_interest = gray[y:y + h, x:x + w]\n",
        "            region_of_interest = cv2.resize(region_of_interest, (48, 48))\n",
        "            region_of_interest = img_to_array(region_of_interest)\n",
        "            region_of_interest = np.expand_dims(region_of_interest, axis=0)\n",
        "\n",
        "            result = model.predict(region_of_interest)[0]\n",
        "            print(result)\n",
        "\n",
        "            if result is not None:\n",
        "                final_result = np.argmax(result)\n",
        "                cv2.putText(frame, expression[final_result], (x, y - 10), font, medium_font, (255, 255, 255), 1, cv2.LINE_AA)\n",
        "    \n",
        "    cv2.putText(frame, \"frame processado em {:.2f} segundos \".format(time.time() - t), (20, video_height - 20), font, small_font,(250, 250, 250), 0, lineType=cv2.LINE_AA)\n",
        "    cv2_imshow(frame)\n",
        "    output_video.write(frame)\n",
        "output_video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7-RhB4x0kUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(time.time())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}